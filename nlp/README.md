# Natural Language Processing

Natural Language Processing (NLP) is a field of artificial intelligence that focuses on the interaction between computers and human language. It enables machines to understand, interpret, and generate human language, allowing for tasks like translation, sentiment analysis, speech recognition, and text summarization. NLP combines linguistics, machine learning, and deep learning to process and analyze large amounts of natural language data, enabling computers to handle tasks like understanding context, meaning, and intent in text or speech.

Common topics:

- Text Preprocessing and Tokenization
- Embedding and Representation Techniques
    - Word2Vec, GloVe, FastText, Transformers
    - Language Modeling
    - RNNs for Language Modeling, Transformer Models (BERT, GPT)
    - Text Classification and Sequence Modeling
    - Applications in Sentiment Analysis, Chatbots, Translation

## Vectorization

Word2Vec is a machine learning model used in Natural Language Processing (NLP) to represent words as vectors in a continuous space. It captures semantic relationships between words by analyzing their context in large text corpora. Word2Vec has two main models: Continuous Bag of Words (CBOW), which predicts a word based on its surrounding context, and Skip-gram, which predicts the surrounding context from a given word. These word embeddings help in various NLP tasks like text classification, machine translation, and analogy reasoning.

### Word2Vec

Word2Vec is a machine learning model used in Natural Language Processing (NLP) to represent words as vectors in a continuous space. It captures semantic relationships between words by analyzing their context in large text corpora. Word2Vec has two main models: Continuous Bag of Words (CBOW), which predicts a word based on its surrounding context, and Skip-gram, which predicts the surrounding context from a given word. These word embeddings help in various NLP tasks like text classification, machine translation, and analogy reasoning.

##### Original Paper

**[Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/pdf/1301.3781)